from google.colab import files
uploaded = files.upload()


%matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras import optimizers
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier

seed = 7
np.random.seed(seed)

df=pd.read_excel('Quasi-yagi_truncado.xlsx')
data=df.copy()
x=data.drop(labels=['G1','G2','G3'],axis=1)
y=data[['G2']]

X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=seed)

from sklearn.preprocessing import StandardScaler
std = StandardScaler()
X_train_std = std.fit_transform(X_train)
X_test_std = std.transform(X_test)

# Function to create model, required for KerasClassifier
def create_model(dense_layer_sizes,optimizer='adam',neurons=1,learning_rate=0.001,init='glorot_uniform'):
	# create model
 model = Sequential()
 model.add(Dense(neurons, input_dim=6, init=init, activation='relu'))
 for layer_size in dense_layer_sizes:
	 model.add(Dense(layer_size,init=init,activation='relu'))
	 
 #model.add(Dense(neurons,init=init, activation='relu'))
 #model.add(Dense(neurons, activation='relu'))
 model.add(Dense(1,init=init))
	# Compile model
 model.compile(loss='mean_squared_error', optimizer=optimizer)
 return model
 
 # fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# load dataset
#dataset = numpy.loadtxt("Quasi-Yagi.xlsx", delimiter=",")
# split into input (X) and output (Y) variables
#X = dataset[:,0:8]
#Y = dataset[:,8]
# create model

eval_set = [(X_train_std, y_train), (X_test_std, y_test)]
model = KerasRegressor(build_fn=create_model, batch_size=10, verbose=1)
# define the grid search parameters
optimizer = [ 'Adam','rmsprop','sgd', 'Nadam']
init = ['normal' , 'uniform','glorot_uniform']
dense_layer_sizes = [(5,5,5),(15,15,15)]
learning_rate=[0.001,0.01]
epochs = [400]
neurons = [10]
param_grid = dict(optimizer=optimizer,epochs=epochs,init=init,neurons=neurons,dense_layer_sizes=dense_layer_sizes,learning_rate=learning_rate)
grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3,scoring="neg_mean_squared_error", verbose=1)
grid_result = grid.fit(X_train_std,y_train)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

final_model = grid.best_estimator_
#xg_reg.fit(X_train,y_train)
preds = final_model.predict(X_test_std)
rmse = np.sqrt(mean_squared_error(y_test, preds))
print("RMSE: %f" % (rmse))

def plot_target_var(var_name, var_indx, y_true, y_pred):
   if var_indx is not None:
    target_true = y_true[:, var_indx]
    target_pred = y_pred[:, var_indx]
   else:
     target_true = y_true.values.ravel()
     target_pred = y_pred.ravel()
     num_instances = range(len(target_true))
     idxs = np.argsort(target_true)
     plt.figure(figsize=(15, 8))
     plt.scatter(num_instances, target_true[idxs], s=20, c='w',alpha=0.5, linewidths=1,edgecolors='b',label='Original Data')
     plt.scatter(num_instances, target_pred[idxs], s=20, c='w', alpha=0.5, linewidths=1,edgecolors='r',label='Predicted Data')
     plt.ylabel(var_name)
     plt.xlabel('Ordered target variables')
     plt.legend()
     
     
plot_target_var(var_name='G2', var_indx=None, y_true=y_test, y_pred=preds)


