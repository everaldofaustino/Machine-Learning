from google.colab import files
uploaded = files.upload()

%matplotlib inline

import re
import xgboost as xgb
import seaborn as sns
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from matplotlib import pyplot
from xgboost.sklearn import XGBRegressor 
from sklearn.model_selection import GridSearchCV 
from sklearn.model_selection import StratifiedKFold 
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

from sklearn.multioutput import MultiOutputRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

from sklearn.pipeline import Pipeline

regex = re.compile(r"\[|\]|<", re.IGNORECASE)


df = pd.read_excel('Quasi-Yagi.xlsx')
data = df.copy()
x = data.drop(labels=['G1', 'G2', 'G3'], axis=1) 
y = data[['G2']]

corr = df.corr()
plt.figure(figsize=(10,7))
plt.title('Correlação Quasi-Yagi Database')
sns.heatmap(corr, annot=True, cbar=False, cmap='Reds')

plt.figure(figsize=(10, 7))
sns.distplot(df['G1'])
plt.title('Distribuicao de G1 ')

plt.figure(figsize=(10, 7))
sns.distplot(df['G2'])
plt.title('Distribuicao de G2 ')

plt.figure(figsize=(10, 7))
sns.distplot(df['G3'])
plt.title('Distribuicao de G3 ')

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=123)
X_train.columns = [regex.sub("_", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]
X_test.columns = [regex.sub("_", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]

std = StandardScaler()
X_train_std = std.fit_transform(X_train)
X_test_std = std.transform(X_test)

 def  plot_var(var_name,y_true,y_pred): 
    
    target_true = y_test.values.ravel()
    target_pred = preds.ravel()     
    
   
    num_instances = range(len(target_true))
    z = np.argsort(target_true)
    plt.figure(figsize=(15, 8))
    plt.scatter(num_instances, target_true[z], s=40, c= 'r', marker='x',
                                                  alpha=0.5, linewidths=1,
                                                  edgecolors='w', label='Original Data')
    plt.scatter(num_instances, target_pred[z], s=40, c='w', marker='o',
                                                  alpha=0.5, linewidths=1,
                                                  edgecolors='b', label='Predicted Data')
    plt.ylabel(var_name)
    plt.xlabel('Ordered target variables')
    plt.legend()
    
    model = XGBRegressor()
n_estimators = [700,800]
learning_rate = [0.0001, 0.001, 0.01]
subsample = [0.5, 0.75, 1.0]
colsample_bytree = [0.4, 0.8, 1.0]
max_depth = [ 6, 8, 10]
min_child_weight = [5]

    
param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators,subsample=subsample,colsample_bytree=colsample_bytree,max_depth=max_depth,min_child_weight=min_child_weight)
kfold = KFold(n_splits=15, shuffle=True, random_state=7)
grid_search = GridSearchCV(model, param_grid, scoring="neg_mean_squared_error", n_jobs=-1, cv=kfold, verbose=1)

eval_set = [(X_train_std, y_train), (X_test_std, y_test)]
grid_result = grid_search.fit(X_train_std, y_train, eval_metric="rmse",verbose=True, eval_set=eval_set)


final_model = grid_search.best_estimator_
#xg_reg.fit(X_train,y_train)
preds = final_model.predict(X_test_std)
rmse = np.sqrt(mean_squared_error(y_test, preds))
print("RMSE: %f" % (rmse))

results = final_model.evals_result()
epochs = len(results['validation_0']['rmse'])
x_axis = range(0, epochs)
# plot log loss
fig, ax = pyplot.subplots(figsize=(15, 8))
ax.plot(x_axis, results['validation_0']['rmse'], label='Train')
ax.plot(x_axis, results['validation_1']['rmse'], label='Test')
ax.legend()
pyplot.ylabel('RMSE')
pyplot.title('XGBoost RMSE G1 - learning curve')
pyplot.show()
